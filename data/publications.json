{
  "publications": [
    {
      "id": "d97Q8r7ZKZ",
      "title": "AlphaBench: Benchmarking Large Language Models in Formulaic Alpha Factor Mining",
      "authors": [
        "Haochen Luo",
        "Ho Tin Ko",
        "Jiandong Chen",
        "David Sun",
        "Yuan Zhang",
        "Chen Liu"
      ],
      "venue": "ICLR 2026 Poster",
      "year": 2025,
      "status": "Published",
      "abstract": "Formulaic alpha factor mining (FAFM) is a central problem in quantitative investment, where interpretable formulas are designed to extract predictive signals from historical financial series. With the emergence of large language models (LLMs), recent studies have begun to explore their roles in FAFM, yet their capabilities across different tasks and configurations remain unclear. In this work, we introduce AlphaBench, the first systematic benchmark for evaluating LLMs in FAFM. AlphaBench covers three core tasks, including factor generation, factor evaluation, and factor searching, which are all popular tasks integrated in the workflow of quantitative researchers. Beyond task-level evaluation, we further analyze how different LLM settings, including model type, prompting paradigm, and reasoning strategy, influence performance. Our experiments on a range of open-source and closed-source models reveal that LLMs hold strong potential in automating factor mining, while also facing persistent challenges in robustness, search efficiency, and practical usability.",
      "openreviewUrl": "https://openreview.net/forum?id=d97Q8r7ZKZ",
      "tags": [
        "Alpha Mining",
        "LLM Benchmark",
        "LLM Agent",
        "Data Science and Engineering"
      ],
      "type": "Publication",
      "fetchedAt": "2026-02-21T01:07:31.985Z"
    },
    {
      "id": "ALpLmURYWy",
      "title": "EvoAlpha: Evolutionary Alpha Factor Discovery with Large Language Models",
      "authors": [
        "Haochen Luo",
        "Ho Tin Ko",
        "David Sun",
        "Yuan Zhang",
        "Chen Liu"
      ],
      "venue": "GenAI in Finance Poster",
      "year": 2025,
      "status": "Published",
      "abstract": "Alpha factor discovery is a central challenge in quantitative finance, traditionally addressed by human experts or automated search methods such as genetic programming and evolutionary algorithms. These approaches often lack semantic guidance, leading to inefficient search and fragile results. We propose a language-model-guided evolutionary framework, where large language models (LLMs) act as intelligent operators to guide mutation, crossover, and selection of candidate factors. By embedding evolutionary instructions into prompts, the LLM leverages domain knowledge and backtesting feedback to generate interpretable and high-quality signals. We first validate the approach through static factor searching, showing that LLMs can iteratively refine factors in a controlled setting. We then evaluate the framework in sparse portfolio optimization, where LLM-generated factors are used to rank assets and construct portfolios under $\\ell_0$ constraints. Experiments on multiple real-market datasets demonstrate consistent improvements in portfolio performance over traditional baselines, highlighting the promise of combining LLMs with evolutionary search for systematic factor discovery.",
      "openreviewUrl": "https://openreview.net/forum?id=ALpLmURYWy",
      "tags": [
        "Alpha factor discovery; Evolutionary search; Large language models; Quantitative finance"
      ],
      "type": "Publication",
      "fetchedAt": "2026-02-21T01:07:31.985Z"
    }
  ],
  "lastUpdated": "2026-02-21T01:07:31.985Z",
  "totalCount": 2,
  "source": "OpenReview API v2 (GitHub Actions)"
}